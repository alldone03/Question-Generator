{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.090909090909092,
  "eval_steps": 500,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 30799.298828125,
      "learning_rate": 1.9e-05,
      "loss": 31.0878,
      "step": 20
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 6965.087890625,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 29.3937,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_loss": 18.50555992126465,
      "eval_runtime": 0.9774,
      "eval_samples_per_second": 10.231,
      "eval_steps_per_second": 5.116,
      "step": 44
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 3948.831787109375,
      "learning_rate": 4.884615384615385e-05,
      "loss": 23.2825,
      "step": 60
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 4192.34619140625,
      "learning_rate": 4.6282051282051287e-05,
      "loss": 17.84,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_loss": 14.67857837677002,
      "eval_runtime": 0.9746,
      "eval_samples_per_second": 10.261,
      "eval_steps_per_second": 5.13,
      "step": 88
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 2754.813232421875,
      "learning_rate": 4.371794871794872e-05,
      "loss": 16.7823,
      "step": 100
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 3151.020751953125,
      "learning_rate": 4.115384615384615e-05,
      "loss": 15.6438,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_loss": 11.91430950164795,
      "eval_runtime": 0.9756,
      "eval_samples_per_second": 10.25,
      "eval_steps_per_second": 5.125,
      "step": 132
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 6163.43115234375,
      "learning_rate": 3.858974358974359e-05,
      "loss": 14.6109,
      "step": 140
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 2433.863037109375,
      "learning_rate": 3.6025641025641024e-05,
      "loss": 14.7199,
      "step": 160
    },
    {
      "epoch": 4.0,
      "eval_loss": 9.785513877868652,
      "eval_runtime": 0.9772,
      "eval_samples_per_second": 10.233,
      "eval_steps_per_second": 5.117,
      "step": 176
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 2102.46923828125,
      "learning_rate": 3.346153846153846e-05,
      "loss": 13.4694,
      "step": 180
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 5680.15869140625,
      "learning_rate": 3.08974358974359e-05,
      "loss": 12.6218,
      "step": 200
    },
    {
      "epoch": 5.0,
      "grad_norm": 652.5381469726562,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 11.1885,
      "step": 220
    },
    {
      "epoch": 5.0,
      "eval_loss": 7.643498420715332,
      "eval_runtime": 0.6889,
      "eval_samples_per_second": 14.517,
      "eval_steps_per_second": 7.258,
      "step": 220
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 411.2662353515625,
      "learning_rate": 2.5769230769230768e-05,
      "loss": 10.5115,
      "step": 240
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 668.208984375,
      "learning_rate": 2.3205128205128207e-05,
      "loss": 9.7626,
      "step": 260
    },
    {
      "epoch": 6.0,
      "eval_loss": 6.709310054779053,
      "eval_runtime": 0.9799,
      "eval_samples_per_second": 10.205,
      "eval_steps_per_second": 5.103,
      "step": 264
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 983.7000122070312,
      "learning_rate": 2.064102564102564e-05,
      "loss": 9.5571,
      "step": 280
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 948.4484252929688,
      "learning_rate": 1.8076923076923076e-05,
      "loss": 9.2106,
      "step": 300
    },
    {
      "epoch": 7.0,
      "eval_loss": 6.376339912414551,
      "eval_runtime": 0.9939,
      "eval_samples_per_second": 10.062,
      "eval_steps_per_second": 5.031,
      "step": 308
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 279.2192687988281,
      "learning_rate": 1.5512820512820516e-05,
      "loss": 9.1712,
      "step": 320
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 2394.1630859375,
      "learning_rate": 1.294871794871795e-05,
      "loss": 10.1699,
      "step": 340
    },
    {
      "epoch": 8.0,
      "eval_loss": 5.889774322509766,
      "eval_runtime": 0.989,
      "eval_samples_per_second": 10.111,
      "eval_steps_per_second": 5.056,
      "step": 352
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 950.6284790039062,
      "learning_rate": 1.0384615384615386e-05,
      "loss": 9.09,
      "step": 360
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 239.46961975097656,
      "learning_rate": 7.82051282051282e-06,
      "loss": 9.0258,
      "step": 380
    },
    {
      "epoch": 9.0,
      "eval_loss": 5.6515793800354,
      "eval_runtime": 0.9885,
      "eval_samples_per_second": 10.116,
      "eval_steps_per_second": 5.058,
      "step": 396
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 522.5230712890625,
      "learning_rate": 5.256410256410257e-06,
      "loss": 8.8954,
      "step": 400
    }
  ],
  "logging_steps": 20,
  "max_steps": 440,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 209120502743040.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
